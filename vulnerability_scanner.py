# vulnerability_scanner.py

import openai
import os
import sys
import subprocess
import json
import re
import logging
import requests
import tiktoken

# Configure logging
def configure_logging():
    os.makedirs('debug_data', exist_ok=True)
    logging.basicConfig(
        filename='debug_data/vulnerability_scanner.log',
        filemode='a',
        format='%(asctime)s - %(levelname)s - %(message)s',
        level=logging.INFO
    )

# Function to check if the web server is responsive
def is_web_server_responsive(host, port=80, timeout=5):
    try:
        response = requests.get(f'http://{host}:{port}', timeout=timeout)
        if response.status_code == 200:
            logging.info(f"Web server on {host}:{port} is responsive.")
            return True
        else:
            logging.warning(f"Web server on {host}:{port} returned status code {response.status_code}.")
            return False
    except requests.RequestException as e:
        logging.error(f"Error accessing web server on {host}:{port}: {str(e)}")
        return False

# Function to run testssl and capture the raw output
def run_testssl_raw(host):
    try:
        # Run testssl.sh with JSON output
        result = subprocess.run(
            ['testssl', '--jsonfile', 'testssl_output.json', host],
            capture_output=True,
            text=True,
            check=True
        )
        # Read the raw output
        with open('testssl_output.json', 'r') as f:
            ssl_data = f.read()
        logging.info("testssl completed successfully.")
        return ssl_data
    except subprocess.CalledProcessError as e:
        error_msg = f"Error running testssl: {e.stderr.strip()}"
        logging.error(error_msg)
        return ""
    except Exception as e:
        error_msg = f"Unexpected error during testssl: {str(e)}"
        logging.error(error_msg)
        return ""

# Function to run Nmap scan and capture the raw output
def run_nmap_raw(host):
    try:
        # Run Nmap with XML output
        result = subprocess.run(
            ['nmap', '-sV', '-Pn', '-oX', 'nmap_output.xml', host],
            capture_output=True,
            text=True,
            check=True
        )
        # Read the raw XML output
        with open('nmap_output.xml', 'r') as f:
            nmap_data = f.read()
        logging.info("Nmap scan completed successfully.")
        return nmap_data
    except subprocess.CalledProcessError as e:
        error_msg = f"Error running Nmap: {e.stderr.strip()}"
        logging.error(error_msg)
        return ""
    except Exception as e:
        error_msg = f"Unexpected error during Nmap scan: {str(e)}"
        logging.error(error_msg)
        return ""

# Function to run Nikto scan and capture the raw output
def run_nikto_raw(host):
    try:
        nikto_path = '/usr/bin/nikto'  # Adjust if necessary
        # Run Nikto with XML output
        result = subprocess.run(
            [nikto_path, '-h', host, '-Format', 'xml', '-o', 'nikto_output.xml'],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        logging.info(f"Nikto stdout: {result.stdout}")
        logging.info(f"Nikto stderr: {result.stderr}")

        # Read the raw XML output
        with open('nikto_output.xml', 'r') as f:
            nikto_data = f.read()
        logging.info("Nikto scan completed successfully.")
        return nikto_data
    except Exception as e:
        error_msg = f"Unexpected error during Nikto scan: {str(e)}"
        logging.error(error_msg)
        return ""

# Function to run WhatWeb scan and capture the raw output
def run_whatweb_raw(host):
    try:
        whatweb_path = '/usr/bin/whatweb'  # Adjust if necessary
        # Run WhatWeb with JSON output
        result = subprocess.run(
            [whatweb_path, host, '--log-json=whatweb_output.json', '--colour=never'],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            check=True
        )
        logging.info(f"WhatWeb stdout: {result.stdout}")
        logging.info(f"WhatWeb stderr: {result.stderr}")

        # Read the raw JSON output
        with open('whatweb_output.json', 'r') as f:
            whatweb_data = f.read()
        logging.info("WhatWeb scan completed successfully.")
        return whatweb_data
    except Exception as e:
        error_msg = f"Unexpected error during WhatWeb scan: {str(e)}"
        logging.error(error_msg)
        return ""

# Function to run Gobuster scan and capture the raw output
def run_gobuster_raw(host):
    try:
        gobuster_path = '/usr/bin/gobuster'  # Adjust if necessary
        wordlist_path = '/usr/share/wordlists/dirb/common.txt'
        if not os.path.exists(wordlist_path):
            error_msg = f"Gobuster wordlist not found at {wordlist_path}"
            logging.error(error_msg)
            return ""

        result = subprocess.run(
            [gobuster_path, 'dir', '-u', f'http://{host}', '-w', wordlist_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            check=True
        )
        logging.info(f"Gobuster stdout: {result.stdout}")
        logging.info(f"Gobuster stderr: {result.stderr}")

        # Get the raw output
        gobuster_data = result.stdout
        logging.info("Gobuster scan completed successfully.")
        return gobuster_data
    except Exception as e:
        error_msg = f"Unexpected error during Gobuster scan: {str(e)}"
        logging.error(error_msg)
        return ""

# Function to prepare raw data for GPT-4
def prepare_raw_data(nmap_data, nikto_data, whatweb_data, gobuster_data, testssl_data):
    raw_data_sections = {
        "Nmap Scan Output": nmap_data.strip() if nmap_data else "",
        "Nikto Scan Output": nikto_data.strip() if nikto_data else "",
        "WhatWeb Scan Output": whatweb_data.strip() if whatweb_data else "",
        "Gobuster Scan Output": gobuster_data.strip() if gobuster_data else "",
        "testssl Output": testssl_data.strip() if testssl_data else "",
    }

    # Save raw data sections for debugging
    os.makedirs('debug_data', exist_ok=True)
    for section_name, data in raw_data_sections.items():
        filename = section_name.lower().replace(' ', '_') + '.txt'
        with open(f'debug_data/{filename}', 'w', encoding='utf-8') as f:
            f.write(data)
        logging.info(f"Raw data for {section_name} saved to debug_data/{filename}")

    return raw_data_sections

# Function to estimate token usage
def estimate_token_usage(prompt, model="gpt-4"):
    encoding = tiktoken.encoding_for_model(model)
    num_tokens = len(encoding.encode(prompt))
    logging.info(f"Estimated tokens used: {num_tokens}")
    return num_tokens

# Function to extract vulnerabilities using GPT-4
def extract_vulnerabilities_from_section(section_name, raw_data):
    try:
        if not raw_data.strip():
            logging.info(f"No raw data for {section_name}. Skipping GPT-4 extraction.")
            return ""

        system_message = (
            "You are a cybersecurity expert tasked with analyzing raw scan outputs from various tools. "
            "Your job is to extract and summarize **all** the vulnerabilities found in the data provided below, "
            "providing concise titles for each 'Finding'. For each finding, include an Impact and Likelihood, each with a "
            "Low/Medium/High rating **and** a description. Also, provide remediation recommendations.\n\n"
            "Important Instructions:\n"
            "- Analyze the raw data thoroughly and include **every** vulnerability found, without omitting any.\n"
            "- For **Impact**, provide both a rating ('Low', 'Medium', or 'High') and a description of the potential impact.\n"
            "- For **Likelihood**, provide both a rating ('Low', 'Medium', or 'High') and a description of how likely the vulnerability is to be exploited.\n"
            "- Output **only** the vulnerabilities in the following JSON format and nothing else.\n"
            "- Do **not** include any explanations, introductions, or conclusions.\n"
            "- Ensure the JSON is valid and properly formatted.\n\n"
            "JSON Format:\n"
            "[\n"
            "  {\n"
            "    \"Finding\": \"Concise Vulnerability Title\",\n"
            "    \"Impact\": {\n"
            "      \"Rating\": \"Low/Medium/High\",\n"
            "      \"Description\": \"Description of the potential impact\"\n"
            "    },\n"
            "    \"Likelihood\": {\n"
            "      \"Rating\": \"Low/Medium/High\",\n"
            "      \"Description\": \"Description of the likelihood of exploitation\"\n"
            "    },\n"
            "    \"Remediation\": \"Recommended remediation steps\"\n"
            "  },\n"
            "  ...\n"
            "]"
        )
        user_message = (
            f"## {section_name}\n"
            f"{raw_data}"
        )

        # Estimate token usage
        total_tokens = estimate_token_usage(system_message + user_message)
        logging.info(f"Estimated tokens used: {total_tokens}")

        if total_tokens > 6000:
            logging.warning(f"Token usage for {section_name} is high: {total_tokens} tokens. Consider reducing raw data size.")

        openai.api_key = os.getenv("OPENAI_API_KEY")
        if not openai.api_key:
            raise ValueError("OpenAI API key not set in environment variable 'OPENAI_API_KEY'.")

        response = openai.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message}
            ],
            temperature=0.2,
            max_tokens=1500  # Adjust based on expected response size
        )

        gpt_response = response.choices[0].message.content.strip()

        # Save GPT-4 response to a file for debugging
        os.makedirs('debug_data', exist_ok=True)
        filename = section_name.lower().replace(' ', '_') + '_gpt_response.txt'
        with open(f'debug_data/{filename}', 'w', encoding='utf-8') as f:
            f.write(gpt_response)

        logging.info(f"GPT-4 response for {section_name} saved to debug_data/{filename}")
        return gpt_response
    except Exception as e:
        error_msg = f"Error during GPT vulnerability extraction for {section_name}: {str(e)}"
        logging.error(error_msg)
        return ""

# Function to parse GPT-4's JSON response
def parse_vulnerabilities(gpt_response):
    try:
        # Attempt to parse the response directly
        vulnerabilities = json.loads(gpt_response)
    except json.JSONDecodeError:
        # If parsing fails, try to extract the JSON content from the response
        try:
            # Use regex to find the JSON array in the response
            json_match = re.search(r'(\[\s*{[\s\S]*}\s*\])', gpt_response)
            if json_match:
                json_str = json_match.group(1)
                vulnerabilities = json.loads(json_str)
            else:
                raise ValueError("No JSON data found in GPT response.")
        except Exception as e:
            logging.error(f"Error parsing GPT response: {str(e)}")
            logging.error(f"GPT response was:\n{gpt_response}")
            vulnerabilities = []
            # Save the error and response to a file for debugging
            try:
                os.makedirs('debug_data', exist_ok=True)
                with open('debug_data/parse_error.txt', 'w', encoding='utf-8') as f:
                    f.write(f"Error parsing GPT response: {str(e)}\n")
                    f.write("GPT response was:\n")
                    f.write(gpt_response)
                logging.info("Parsing error details saved to debug_data/parse_error.txt")
            except Exception as ex:
                logging.error(f"Error saving parsing error details: {str(ex)}")
    else:
        # Save vulnerabilities to a JSON file for debugging
        try:
            os.makedirs('debug_data', exist_ok=True)
            with open('debug_data/vulnerabilities.json', 'w', encoding='utf-8') as f:
                json.dump(vulnerabilities, f, indent=2)
            logging.info("Vulnerabilities saved to debug_data/vulnerabilities.json")
        except Exception as e:
            logging.error(f"Error saving vulnerabilities: {str(e)}")

    return vulnerabilities

# Function to generate the final report with GPT-4
def generate_report_with_gpt(host, vulnerabilities):
    try:
        # Summarize or limit vulnerabilities if necessary
        if len(vulnerabilities) > 20:
            logging.info(f"Reducing vulnerabilities from {len(vulnerabilities)} to 20 to stay within token limits.")
            vulnerabilities = vulnerabilities[:20]  # Keep only the first 20 vulnerabilities

        prompt_content = (
            f"You are a professional penetration tester. Using the following vulnerabilities, generate a detailed vulnerability report for the host {host}.\n\n"
            "The report should include:\n"
            "- An Overview section summarizing the overall security posture.\n"
            "- A Vulnerability Findings section with a table containing 'Vulnerability Finding', 'Impact', 'Likelihood', and 'Remediation' columns.\n"
            "- Ensure that the 'Vulnerability Finding' entries are concise titles.\n"
            "- Expand on the impact, likelihood, and remediation for each finding.\n\n"
            "Vulnerabilities:\n"
            f"{json.dumps(vulnerabilities, indent=2)}"
        )

        # Estimate token usage
        total_tokens = estimate_token_usage(prompt_content)
        logging.info(f"Total tokens in prompt: {total_tokens}")

        # Adjust max_tokens accordingly
        max_completion_tokens = 8192 - total_tokens - 500  # Reserve 500 tokens for safety
        if max_completion_tokens > 2000:
            max_completion_tokens = 2000  # Set an upper limit for completion tokens

        openai.api_key = os.getenv("OPENAI_API_KEY")

        response = openai.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "user", "content": prompt_content}
            ],
            temperature=0.2,
            max_tokens=max_completion_tokens
        )

        return response.choices[0].message.content.strip()
    except Exception as e:
        error_msg = f"Error during GPT report generation: {str(e)}"
        logging.error(error_msg)
        return ""

# Function to validate the GPT-generated report format
def validate_report(report_content):
    try:
        # Check for main title
        if not re.search(r'^#\s+Vulnerability Report for .+', report_content, re.MULTILINE):
            raise ValueError("Main title missing or incorrectly formatted.")

        # Check for Overview section
        if not re.search(r'^##\s+Overview\s*\n\n.+', report_content, re.MULTILINE | re.DOTALL):
            raise ValueError("Overview section missing or incorrectly formatted.")

        # Check for Vulnerability Findings section
        if not re.search(r'^##\s+Vulnerability Findings\s*\n\n\|', report_content, re.MULTILINE):
            raise ValueError("Vulnerability Findings section missing or incorrectly formatted.")

        logging.info("GPT-generated report format is valid.")
        return True, ""
    except Exception as e:
        return False, str(e)

# Function to save the report to a Markdown file
def save_report(content, output_file):
    try:
        with open(output_file, 'w', encoding='utf-8') as file:
            file.write(content)
        logging.info(f"Report saved to {output_file}")
    except Exception as e:
        logging.error(f"Error saving report: {str(e)}")
        print(f"Error saving report: {str(e)}")

# Function to clean up temporary files
def clean_up_temp_files():
    try:
        temp_files = [
            'testssl_output.json',
            'nmap_output.xml',
            'nikto_output.xml',
            'whatweb_output.json'
        ]
        for temp_file in temp_files:
            if os.path.exists(temp_file):
                os.remove(temp_file)
    except Exception as e:
        logging.error(f"Error cleaning up temporary files: {str(e)}")
